{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-attention Generative Adversarial Capsule Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import skimage\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from keras import layers, models, optimizers\n",
    "from keras.layers import Input\n",
    "from keras.models import Sequential, Model\n",
    "from keras import callbacks, backend\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from utils import load_image, load_faces\n",
    "from discriminator import discriminator_func\n",
    "from generator import generator_func\n",
    "from attention import self_attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip\n",
    "\n",
    "with zipfile.ZipFile(\"celeba.zip\",\"r\") as zip_ref:\n",
    "  zip_ref.extractall(\"data_faces/\")\n",
    "\n",
    "root = 'data_faces/img_align_celeba'\n",
    "img_list = os.listdir(root)\n",
    "print(\"Total Number of Images : \", len(img_list))\n",
    "required_size = (32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'directory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-412609b27c17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data_faces/img_align_celeba/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loaded: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'directory' is not defined"
     ]
    }
   ],
   "source": [
    "number_of_images = 8000\n",
    " \n",
    "\n",
    "root = 'data_faces/img_align_celeba/'\n",
    "dataset = load_faces(directory, number_of_images)\n",
    "print('Loaded: ', dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "\tix = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "\tX = dataset[ix]\n",
    "\ty = np.ones((n_samples, 1))\n",
    "\treturn X, y\n",
    " \n",
    "\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "\tx_input = np.random.randn(latent_dim * n_samples)\n",
    "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
    "\treturn x_input\n",
    " \n",
    "\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
    "\tX = generator.predict(x_input)\n",
    "\ty = np.zeros((n_samples, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISCRIMINATOR\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 28, 28, 16)   1216        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_7 (self_attentio (None, 28, 28, 16)   321         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 28, 28, 16)   0           self_attention_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_conv2 (Conv2DTranspo (None, 32, 32, 32)   12832       leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_8 (self_attentio (None, 32, 32, 32)   1281        primarycap_conv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 32, 32, 32)   0           self_attention_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_reshape (Reshape)    (None, 4096, 8)      0           leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_squash (Lambda)      (None, 4096, 8)      0           primarycap_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 32768)        0           primarycap_squash[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "uhat_digitcaps (Dense)          (None, 256)          8388864     flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "softmax_digitcaps1 (Activation) (None, 256)          0           uhat_digitcaps[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          65792       softmax_digitcaps1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 256)          0           uhat_digitcaps[0][0]             \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 256)          0           multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "softmax_digitcaps2 (Activation) (None, 256)          0           leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 256)          65792       softmax_digitcaps2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 256)          0           uhat_digitcaps[0][0]             \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 256)          0           multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "softmax_digitcaps3 (Activation) (None, 256)          0           leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          65792       softmax_digitcaps3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 256)          0           uhat_digitcaps[0][0]             \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 256)          0           multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            257         leaky_re_lu_18[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 8,602,147\n",
      "Trainable params: 8,602,147\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "\n",
    "discriminator = discriminator_func(input_shape)\n",
    "\n",
    "print('DISCRIMINATOR')\n",
    "\n",
    "discriminator.summary()\n",
    "\n",
    "discriminator.compile(loss = 'binary_crossentropy', optimizer = Adam(0.0004, 0.48), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Buidling Generator from Random Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATOR\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 16384)             1654784   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "gaussian_noise_3 (GaussianNo (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 16, 16, 16)        102416    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 32, 32, 16)        6416      \n",
      "_________________________________________________________________\n",
      "self_attention_9 (self_atten (None, 32, 32, 16)        321       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 64, 64, 32)        12832     \n",
      "_________________________________________________________________\n",
      "self_attention_10 (self_atte (None, 64, 64, 32)        1281      \n",
      "_________________________________________________________________\n",
      "pixel_normalization_3 (pixel (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "gaussian_dropout_3 (Gaussian (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 3)         2403      \n",
      "=================================================================\n",
      "Total params: 1,780,453\n",
      "Trainable params: 1,780,453\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = generator_func(100)\n",
    "\n",
    "print('GENERATOR')\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMBINED\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (None, 64, 64, 3)         1780453   \n",
      "_________________________________________________________________\n",
      "model_3 (Model)              (None, 1)                 8602147   \n",
      "=================================================================\n",
      "Total params: 10,382,600\n",
      "Trainable params: 1,780,453\n",
      "Non-trainable params: 8,602,147\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "z = Input(shape=(100,))\n",
    "\n",
    "img = generator(z)\n",
    "\n",
    "discriminator.trainable = False\n",
    "\n",
    "valid = discriminator(img)\n",
    "\n",
    "combined = Model(z, valid)\n",
    "\n",
    "print('COMBINED')\n",
    "\n",
    "combined.summary()\n",
    "\n",
    "combined.compile(loss='binary_crossentropy', optimizer=Adam(lr = 0.0004))\n",
    "\n",
    "def define_gan(generator, discriminator):\n",
    "\n",
    "\tdiscriminator.trainable = False\n",
    "\n",
    "\tmodel = Sequential()\n",
    "\n",
    "\tmodel.add(generator)\n",
    "\n",
    "\tmodel.add(discriminator)\n",
    "\n",
    "\topt = Adam(lr=0.0001)\n",
    "    \n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer = opt)\n",
    "    \n",
    "\treturn model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
